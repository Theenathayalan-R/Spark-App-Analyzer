# file: /Users/theenathayalan/Documents/GitHub/Spark-App-Analyzer/spark_analyzer/sql_optimizer.py
# hypothesis_version: 6.138.1

[0.0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1000.0, ' IN ', ' OR ', ', ', 'AQEShuffleRead', 'AVG(', 'AdaptiveSparkPlan', 'BroadcastHashJoin', 'COUNT(DISTINCT', 'CartesianProduct', 'Cross Join', 'Exchange', 'GROUP BY', 'GROUP BY.*HAVING', 'GROUP BY.+HAVING', 'GROUP BY.+ORDER BY', 'JOIN', 'JOIN.*ON', 'Join', 'LIKE', 'ORDER BY', 'PARTITION BY', 'PushedFilters', 'SUM(', 'ShuffleHashJoin', 'ShuffledHashJoin', 'SkewJoin', 'SortMergeJoin', 'WHERE', 'WINDOW', 'WholeStageCodegen', 'broadcast', 'broadcast_join', 'cartesian', 'children', 'complex_agg', 'cost', 'data_skew', 'description', 'duration', 'durationMs', 'duration_ms', 'filter pushdown', 'filter_pushdown', 'metrics', 'name', 'node', 'nodeName', 'numOutputRows', 'optimization', 'outputRows', 'pattern', 'query_id', 'query_plan', 'rowCount', 'rows', 'shuffle', 'sparkPlanInfo', 'spark_plan_info', 'timeMs', '{']