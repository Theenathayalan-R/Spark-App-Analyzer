# file: /Users/theenathayalan/Documents/GitHub/Spark-App-Analyzer/spark_analyzer/root_cause.py
# hypothesis_version: 6.138.2

[0.0, 0.1, 0.15, 0.2, 0.3, 0.5, 0.6, 0.8, 0.85, 0.9, 0.95, 1.0, 1.5, 10.0, 1000000000.0, 5000000000.0, 10000000000.0, 1000, '; ', 'avg_cpu_util', 'avg_duration', 'avg_gc_ratio', 'avg_mem_util', 'cpu_bottleneck', 'cpu_bound', 'cpu_usage', 'critical_path', 'current_duration', 'data_skew', 'degradation_rate', 'dependent_count', 'disk_spill_size', 'duration', 'executor_time', 'executors', 'gc', 'gc_overhead', 'gc_ratio', 'gc_time', 'high_cpu_wait_time', 'high_gc_time', 'initial_duration', 'jobs', 'max_cpu_util', 'max_duration', 'max_mem_util', 'memory_bottleneck', 'memory_pressure', 'memory_usage', 'min_cpu_util', 'min_duration', 'min_mem_util', 'parent_ids', 'path', 'path_duration_ms', 'pattern', 'performance_trend', 'shuffle', 'shuffle_bytes', 'shuffle_read', 'shuffle_read_bytes', 'shuffle_spill', 'shuffle_write', 'shuffle_write_bytes', 'spill_bytes', 'spill_heavy', 'spill_ratio', 'spill_size', 'stage_dependency', 'stage_duration', 'stages', 'std_cpu_util', 'std_mem_util', 'tasks', 'threshold', 'total_time', 'trend_coefficient']